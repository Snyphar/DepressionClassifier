{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "#deal with tensors\n",
    "import torch   \n",
    "from torchsummary import summary\n",
    "#handling text data\n",
    "from torchtext.legacy import data   \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset 1.csv', encoding = \"ISO-8859-1\")\n",
    "df.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SNYPHAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SNYPHAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SNYPHAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "english_stops = set(stopwords.words('english'))\n",
    "nltk.download('punkt')\n",
    "puncset = list(string.punctuation)\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(text):\n",
    "  sentence = [lemmatizer.lemmatize(i, pos='v') for i in text.split() if i not in puncset and i not in english_stops]\n",
    "  # sentence = [lemmatizer.lemmatize(i, pos='v') for i in text.split() if i not in puncset]\n",
    "  sentence = [w for w in sentence if w.isalpha()]\n",
    "  return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df.text.map(lambda x: preprocessData(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           real good miss\n",
       "1                                               read manga\n",
       "2                                                         \n",
       "3          Need send accountant I even refer Those support\n",
       "4                                                ADD ME ON\n",
       "                               ...                        \n",
       "10309    No Depression G Herbo mood do stress people de...\n",
       "10310    What depression succumb brain make feel like n...\n",
       "10311    Ketamine Nasal Spray Shows Promise Against Sui...\n",
       "10312                        dont mistake bad day everyone\n",
       "10313                                                     \n",
       "Name: text, Length: 10314, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words:  12883  max_length:  43  min_length:  0\n"
     ]
    }
   ],
   "source": [
    "sentence_length = []\n",
    "count = Counter()\n",
    "def CountWords():\n",
    "    for i in df.text:\n",
    "        temp = i.split()\n",
    "        sentence_length.append(len(temp))\n",
    "        for j in temp:\n",
    "            count[j] += 1\n",
    "    num_words = len(count)\n",
    "    max_length = max(sentence_length)\n",
    "    min_length = min(sentence_length)\n",
    "    print('num_words: ',num_words,' max_length: ',max_length,' min_length: ',min_length)\n",
    "CountWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[df['text'] == \"\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words:  12883  max_length:  43  min_length:  0\n"
     ]
    }
   ],
   "source": [
    "CountWords()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"train.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducing same results\n",
    "SEED = 2019\n",
    "\n",
    "#Torch\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "#Cuda algorithms\n",
    "torch.backends.cudnn.deterministic = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize='moses',batch_first=True,include_lengths=True)\n",
    "LABEL = data.LabelField(dtype = torch.float,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [(None, None), ('text',TEXT),('label', LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['real', 'good', 'miss'], 'label': '0'}\n"
     ]
    }
   ],
   "source": [
    "#loading custom dataset\n",
    "training_data=data.TabularDataset(path = 'train.csv',format = 'csv',fields = fields,skip_header = True)\n",
    "\n",
    "#print preprocessed text\n",
    "print(vars(training_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_data, test_data = training_data.split(split_ratio=0.8, random_state = random.seed(SEED))\n",
    "train_data, valid_data = train_data.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TEXT vocabulary: 2324\n",
      "Size of LABEL vocabulary: 2\n",
      "[('I', 1783), ('depression', 791), ('get', 553), ('go', 442), ('like', 330), ('love', 328), ('good', 271), ('make', 263), ('see', 232), ('know', 231)]\n",
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x00000269526E7160>>, {'<unk>': 0, '<pad>': 1, 'I': 2, 'depression': 3, 'get': 4, 'go': 5, 'like': 6, 'love': 7, 'good': 8, 'make': 9, 'see': 10, 'day': 11, 'know': 12, 'think': 13, 'time': 14, 'u': 15, 'Depression': 16, 'The': 17, 'feel': 18, 'new': 19, 'one': 20, 'thank': 21, 'want': 22, 'work': 23, 'take': 24, 'come': 25, 'back': 26, 'much': 27, 'really': 28, 'say': 29, 'look': 30, 'watch': 31, 'You': 32, 'need': 33, 'im': 34, 'lol': 35, 'great': 36, 'people': 37, 'help': 38, 'today': 39, 'use': 40, 'try': 41, 'gonna': 42, 'would': 43, 'My': 44, 'anxiety': 45, 'well': 46, 'Just': 47, 'still': 48, 'wait': 49, 'happy': 50, 'hope': 51, 'even': 52, 'night': 53, 'Good': 54, 'haha': 55, 'It': 56, 'way': 57, 'And': 58, 'fun': 59, 'give': 60, 'last': 61, 'right': 62, 'better': 63, 'start': 64, 'follow': 65, 'talk': 66, 'home': 67, 'find': 68, 'eat': 69, 'everyone': 70, 'life': 71, 'twitter': 72, 'never': 73, 'someone': 74, 'We': 75, 'sure': 76, 'guy': 77, 'miss': 78, 'How': 79, 'nice': 80, 'could': 81, 'morning': 82, 'Thanks': 83, 'keep': 84, 'tweet': 85, 'always': 86, 'first': 87, 'What': 88, 'best': 89, 'read': 90, 'ready': 91, 'show': 92, 'So': 93, 'lot': 94, 'tell': 95, 'ur': 96, 'hear': 97, 'us': 98, 'live': 99, 'oh': 100, 'But': 101, 'do': 102, 'Have': 103, 'call': 104, 'enjoy': 105, 'let': 106, 'mental': 107, 'next': 108, 'tomorrow': 109, 'Happy': 110, 'bad': 111, 'A': 112, 'bed': 113, 'every': 114, 'glad': 115, 'sleep': 116, 'leave': 117, 'listen': 118, 'play': 119, 'something': 120, 'If': 121, 'awesome': 122, 'cause': 123, 'days': 124, 'suffer': 125, 'thing': 126, 'buy': 127, 'Great': 128, 'Thank': 129, 'check': 130, 'please': 131, 'things': 132, 'Is': 133, 'This': 134, 'amaze': 135, 'ever': 136, 'little': 137, 'post': 138, 'pretty': 139, 'stop': 140, 'x': 141, 'That': 142, 'cure': 143, 'may': 144, 'cool': 145, 'friends': 146, 'hey': 147, 'real': 148, 'wish': 149, 'also': 150, 'hard': 151, 'school': 152, 'mean': 153, 'weekend': 154, 'LOL': 155, 'another': 156, 'long': 157, 'meet': 158, 'song': 159, 'add': 160, 'beautiful': 161, 'hit': 162, 'sun': 163, 'excite': 164, 'face': 165, 'house': 166, 'world': 167, 'Not': 168, 'music': 169, 'though': 170, 'via': 171, 'already': 172, 'cry': 173, 'dont': 174, 'sound': 175, 'friend': 176, 'tonight': 177, 'At': 178, 'around': 179, 'end': 180, 'fuck': 181, 'many': 182, 'send': 183, 'yeah': 184, 'year': 185, 'Do': 186, 'Hey': 187, 'Oh': 188, 'big': 189, 'shit': 190, 'wanna': 191, 'Now': 192, 'care': 193, 'game': 194, 'happen': 195, 'study': 196, 'support': 197, 'week': 198, 'ask': 199, 'drink': 200, 'finally': 201, 'least': 202, 'sign': 203, 'sorry': 204, 'turn': 205, 'write': 206, 'ya': 207, 'Love': 208, 'No': 209, 'actually': 210, 'might': 211, 'n': 212, 'pay': 213, 'put': 214, 'cant': 215, 'finish': 216, 'movie': 217, 'ok': 218, 'share': 219, 'wake': 220, 'Watching': 221, 'almost': 222, 'cute': 223, 'deal': 224, 'struggle': 225, 'two': 226, 'video': 227, 'THE': 228, 'anyone': 229, 'head': 230, 'later': 231, 'nothing': 232, 'old': 233, 'run': 234, 'sit': 235, 'totally': 236, 'yes': 237, 'In': 238, 'book': 239, 'maybe': 240, 'soon': 241, 'years': 242, 'For': 243, 'Hope': 244, 'To': 245, 'Twitter': 246, 'Well': 247, 'YOU': 248, 'bite': 249, 'bring': 250, 'hair': 251, 'job': 252, 'learn': 253, 'lose': 254, 'nap': 255, 'person': 256, 'plan': 257, 'since': 258, 'stay': 259, 'thats': 260, 'till': 261, 'Going': 262, 'Im': 263, 'Its': 264, 'anything': 265, 'enough': 266, 'everything': 267, 'fight': 268, 'forward': 269, 'free': 270, 'girl': 271, 'guess': 272, 'hand': 273, 'health': 274, 'hot': 275, 'join': 276, 'part': 277, 'place': 278, 'remember': 279, 'shop': 280, 'smile': 281, 'stuff': 282, 'summer': 283, 'Loudly': 284, 'She': 285, 'break': 286, 'kid': 287, 'reason': 288, 'saw': 289, 'sweet': 290, 'train': 291, 'win': 292, 'without': 293, 'All': 294, 'Face': 295, 'LOVE': 296, 'Me': 297, 'Your': 298, 'change': 299, 'dinner': 300, 'luck': 301, 'mom': 302, 'quite': 303, 'skin': 304, 'spend': 305, 'tire': 306, 'Day': 307, 'Got': 308, 'Had': 309, 'Hi': 310, 'On': 311, 'Time': 312, 'When': 313, 'experience': 314, 'followers': 315, 'idea': 316, 'interest': 317, 'link': 318, 'lovely': 319, 'man': 320, 'weather': 321, 'whole': 322, 'xx': 323, 'cut': 324, 'decide': 325, 'early': 326, 'email': 327, 'family': 328, 'far': 329, 'food': 330, 'forget': 331, 'hate': 332, 'hurt': 333, 'party': 334, 'pick': 335, 'red': 336, 'They': 337, 'Why': 338, 'able': 339, 'appreciate': 340, 'away': 341, 'believe': 342, 'blog': 343, 'children': 344, 'crazy': 345, 'development': 346, 'drive': 347, 'else': 348, 'mood': 349, 'move': 350, 'pass': 351, 'rest': 352, 'tie': 353, 'understand': 354, 'visit': 355, 'wonder': 356, 'God': 357, 'June': 358, 'Maybe': 359, 'New': 360, 'die': 361, 'favorite': 362, 'funny': 363, 'mind': 364, 'picture': 365, 'r': 366, 'rock': 367, 'seem': 368, 'speak': 369, 'Anxiety': 370, 'Having': 371, 'Heavy': 372, 'More': 373, 'baby': 374, 'birthday': 375, 'busy': 376, 'coffee': 377, 'definitely': 378, 'fan': 379, 'fix': 380, 'hours': 381, 'ill': 382, 'illness': 383, 'include': 384, 'late': 385, 'must': 386, 'point': 387, 'probably': 388, 'rain': 389, 'severe': 390, 'sing': 391, 'tear': 392, 'vote': 393, 'welcome': 394, 'yet': 395, 'AND': 396, 'Can': 397, 'Get': 398, 'Once': 399, 'Smiling': 400, 'Will': 401, 'album': 402, 'bout': 403, 'cook': 404, 'depress': 405, 'fall': 406, 'hang': 407, 'hopefully': 408, 'intellectual': 409, 'name': 410, 'okay': 411, 'open': 412, 'outside': 413, 'pic': 414, 'save': 415, 'set': 416, 'stress': 417, 'type': 418, 'update': 419, 'worry': 420, 'yesterday': 421, 'Are': 422, 'As': 423, 'He': 424, 'Last': 425, 'Life': 426, 'Lol': 427, 'TO': 428, 'U': 429, 'band': 430, 'beat': 431, 'brain': 432, 'class': 433, 'deserve': 434, 'dream': 435, 'issue': 436, 'kill': 437, 'lead': 438, 'mother': 439, 'number': 440, 'phone': 441, 'realize': 442, 'recommend': 443, 'relax': 444, 'risk': 445, 'sad': 446, 'side': 447, 'super': 448, 'treat': 449, 'wear': 450, 'white': 451, 'worth': 452, 'yay': 453, 'DEPRESSION': 454, 'Morning': 455, 'NOT': 456, 'Nice': 457, 'There': 458, 'With': 459, 'become': 460, 'bitch': 461, 'car': 462, 'chronic': 463, 'dark': 464, 'deep': 465, 'easy': 466, 'especially': 467, 'kind': 468, 'kinda': 469, 'mine': 470, 'room': 471, 'second': 472, 'self': 473, 'site': 474, 'thoughts': 475, 'walk': 476, 'Getting': 477, 'One': 478, 'SO': 479, 'See': 480, 'along': 481, 'answer': 482, 'ass': 483, 'catch': 484, 'chance': 485, 'chat': 486, 'cold': 487, 'damn': 488, 'full': 489, 'hello': 490, 'hi': 491, 'joke': 492, 'kick': 493, 'laugh': 494, 'light': 495, 'past': 496, 'promise': 497, 'question': 498, 'reply': 499, 'social': 500, 'story': 501, 'trip': 502, 'wonderful': 503, 'word': 504, 'Back': 505, 'Check': 506, 'Did': 507, 'Hello': 508, 'IS': 509, 'Like': 510, 'OF': 511, 'Of': 512, 'Off': 513, 'bc': 514, 'bore': 515, 'college': 516, 'concert': 517, 'course': 518, 'cover': 519, 'cripple': 520, 'drug': 521, 'episode': 522, 'fine': 523, 'low': 524, 'short': 525, 'shower': 526, 'stick': 527, 'sunny': 528, 'vip': 529, 'wed': 530, 'wow': 531, 'Been': 532, 'Finally': 533, 'Glad': 534, 'May': 535, 'Or': 536, 'Sunday': 537, 'Wish': 538, 'bless': 539, 'breakfast': 540, 'clean': 541, 'dad': 542, 'dog': 543, 'exactly': 544, 'felt': 545, 'god': 546, 'goodnight': 547, 'gotta': 548, 'guitar': 549, 'half': 550, 'hehe': 551, 'hell': 552, 'hop': 553, 'literally': 554, 'ones': 555, 'pain': 556, 'perfect': 557, 'proud': 558, 'sometimes': 559, 'songs': 560, 'sort': 561, 'state': 562, 'step': 563, 'suck': 564, 'top': 565, 'track': 566, 'xoxo': 567, 'Am': 568, 'Even': 569, 'Friday': 570, 'Goodnight': 571, 'MY': 572, 'ON': 573, 'Only': 574, 'Please': 575, 'THAT': 576, 'Then': 577, 'Today': 578, 'afternoon': 579, 'age': 580, 'aww': 581, 'battle': 582, 'clear': 583, 'close': 584, 'comment': 585, 'control': 586, 'cuz': 587, 'didnt': 588, 'doctor': 589, 'ease': 590, 'film': 591, 'goin': 592, 'ha': 593, 'hat': 594, 'heart': 595, 'hug': 596, 'ice': 597, 'instead': 598, 'less': 599, 'lucky': 600, 'lunch': 601, 'offer': 602, 'page': 603, 'parent': 604, 'power': 605, 'process': 606, 'record': 607, 'remind': 608, 'research': 609, 'safe': 610, 'season': 611, 'sex': 612, 'single': 613, 'soo': 614, 'suicidal': 615, 'suicide': 616, 'surprise': 617, 'teach': 618, 'term': 619, 'test': 620, 'til': 621, 'true': 622, 'weight': 623, 'wrong': 624, 'After': 625, 'Birthday': 626, 'Enjoy': 627, 'FOR': 628, 'Go': 629, 'Haha': 630, 'IT': 631, 'Night': 632, 'Take': 633, 'Welcome': 634, 'Yeah': 635, 'accept': 636, 'ago': 637, 'anyway': 638, 'attention': 639, 'blue': 640, 'build': 641, 'chill': 642, 'develop': 643, 'exercise': 644, 'fact': 645, 'fit': 646, 'hahaha': 647, 'high': 648, 'important': 649, 'level': 650, 'manage': 651, 'medication': 652, 'men': 653, 'message': 654, 'mix': 655, 'money': 656, 'omg': 657, 'online': 658, 'pack': 659, 'paint': 660, 'piece': 661, 'problem': 662, 'round': 663, 'serious': 664, 'shall': 665, 'star': 666, 'together': 667, 'xxx': 668, 'About': 669, 'Be': 670, 'Because': 671, 'Best': 672, 'Could': 673, 'Here': 674, 'Monday': 675, 'Never': 676, 'OMG': 677, 'Read': 678, 'Saturday': 679, 'Sounds': 680, 'US': 681, 'act': 682, 'admit': 683, 'alot': 684, 'asleep': 685, 'beach': 686, 'beer': 687, 'boy': 688, 'cannabis': 689, 'condition': 690, 'congrats': 691, 'contact': 692, 'dance': 693, 'design': 694, 'difficult': 695, 'disorder': 696, 'dress': 697, 'drop': 698, 'everybody': 699, 'figure': 700, 'fill': 701, 'fly': 702, 'group': 703, 'grow': 704, 'hide': 705, 'holiday': 706, 'hour': 707, 'huge': 708, 'improve': 709, 'lower': 710, 'luv': 711, 'mad': 712, 'matter': 713, 'medical': 714, 'model': 715, 'moment': 716, 'news': 717, 'nights': 718, 'others': 719, 'ppl': 720, 'prevent': 721, 'push': 722, 'quit': 723, 'raise': 724, 'rid': 725, 'roll': 726, 'smoke': 727, 'sooo': 728, 'symptoms': 729, 'xD': 730, 'Another': 731, 'Blue': 732, 'By': 733, 'Congrats': 734, 'Does': 735, 'Feel': 736, 'JUST': 737, 'Make': 738, 'Mothers': 739, 'People': 740, 'Up': 741, 'Was': 742, 'Who': 743, 'Wow': 744, 'account': 745, 'article': 746, 'attack': 747, 'avoid': 748, 'awake': 749, 'b': 750, 'bday': 751, 'bipolar': 752, 'body': 753, 'bright': 754, 'cat': 755, 'choiceDepression': 756, 'choose': 757, 'cos': 758, 'da': 759, 'def': 760, 'diagnose': 761, 'door': 762, 'due': 763, 'etc': 764, 'garden': 765, 'graduation': 766, 'hold': 767, 'interview': 768, 'ist': 769, 'lmao': 770, 'longer': 771, 'major': 772, 'mention': 773, 'months': 774, 'movies': 775, 'normal': 776, 'notice': 777, 'office': 778, 'often': 779, 'order': 780, 'peace': 781, 'physical': 782, 'podcast': 783, 'poor': 784, 'positive': 785, 'pray': 786, 'problems': 787, 'regularly': 788, 'relate': 789, 'rise': 790, 'search': 791, 'small': 792, 'soooo': 793, 'special': 794, 'suggest': 795, 'suppose': 796, 'teens': 797, 'text': 798, 'therapy': 799, 'tho': 800, 'trigger': 801, 'truly': 802, 'view': 803, 'wall': 804, 'water': 805, 'worse': 806, 'yall': 807, 'AM': 808, 'Cool': 809, 'DAY': 810, 'FINALLY': 811, 'Follow': 812, 'Glass': 813, 'Heading': 814, 'Health': 815, 'Keep': 816, 'Looking': 817, 'ME': 818, 'Man': 819, 'Mental': 820, 'Most': 821, 'Need': 822, 'Next': 823, 'Should': 824, 'Some': 825, 'Too': 826, 'Trying': 827, 'UP': 828, 'Vaastu': 829, 'Very': 830, 'WITH': 831, 'Went': 832, 'Where': 833, 'addiction': 834, 'agree': 835, 'ah': 836, 'awww': 837, 'bar': 838, 'behind': 839, 'black': 840, 'boys': 841, 'business': 842, 'cake': 843, 'cannot': 844, 'carry': 845, 'color': 846, 'computer': 847, 'consider': 848, 'daily': 849, 'date': 850, 'doin': 851, 'draw': 852, 'dude': 853, 'egg': 854, 'either': 855, 'em': 856, 'everyday': 857, 'fantastic': 858, 'fav': 859, 'final': 860, 'focus': 861, 'front': 862, 'fully': 863, 'healthy': 864, 'higher': 865, 'highly': 866, 'history': 867, 'human': 868, 'internet': 869, 'ive': 870, 'lay': 871, 'lift': 872, 'lil': 873, 'market': 874, 'middle': 875, 'monday': 876, 'nervous': 877, 'panic': 878, 'personal': 879, 'playlist': 880, 'pls': 881, 'pop': 882, 'prepare': 883, 'program': 884, 'pull': 885, 'reduce': 886, 'relationship': 887, 'rn': 888, 'road': 889, 'ruin': 890, 'seriously': 891, 'shake': 892, 'sick': 893, 'straight': 894, 'street': 895, 'stupid': 896, 'team': 897, 'touch': 898, 'tour': 899, 'trouble': 900, 'tv': 901, 'upload': 902, 'w': 903, 'war': 904, 'weeks': 905, 'whatever': 906, 'whats': 907, 'wont': 908, 'worst': 909, 'yo': 910, 'young': 911, 'ALL': 912, 'ARE': 913, 'Avoid': 914, 'BBQ': 915, 'Being': 916, 'Black': 917, 'DM': 918, 'Eating': 919, 'Enjoying': 920, 'Every': 921, 'Exercise': 922, 'Finished': 923, 'Help': 924, 'LA': 925, 'Let': 926, 'Listening': 927, 'Live': 928, 'Moon': 929, 'Ok': 930, 'Our': 931, 'Playing': 932, 'Right': 933, 'Risk': 934, 'Social': 935, 'Suicide': 936, 'THIS': 937, 'Tell': 938, 'Use': 939, 'WE': 940, 'Which': 941, 'Yay': 942, 'Yes': 943, 'actual': 944, 'afraid': 945, 'allow': 946, 'alone': 947, 'annoy': 948, 'arrive': 949, 'associate': 950, 'bag': 951, 'bank': 952, 'bath': 953, 'blame': 954, 'bother': 955, 'bus': 956, 'bye': 957, 'camera': 958, 'continue': 959, 'cost': 960, 'couple': 961, 'cream': 962, 'create': 963, 'dedicate': 964, 'difference': 965, 'dig': 966, 'discuss': 967, 'doubt': 968, 'drama': 969, 'effect': 970, 'enter': 971, 'exam': 972, 'explain': 973, 'eye': 974, 'favourite': 975, 'finger': 976, 'flower': 977, 'force': 978, 'green': 979, 'hahah': 980, 'heal': 981, 'husband': 982, 'increase': 983, 'invite': 984, 'involve': 985, 'jealous': 986, 'lack': 987, 'lazy': 988, 'line': 989, 'marry': 990, 'massive': 991, 'media': 992, 'million': 993, 'minute': 994, 'mostly': 995, 'nite': 996, 'photo': 997, 'porn': 998, 'professional': 999, 'properly': 1000, 'pump': 1001, 'purpose': 1002, 'radio': 1003, 'rainy': 1004, 'response': 1005, 'result': 1006, 'sadDepression': 1007, 'shoot': 1008, 'simply': 1009, 'smell': 1010, 'spread': 1011, 'stand': 1012, 'store': 1013, 'strong': 1014, 'style': 1015, 'suddenly': 1016, 'sunday': 1017, 'swim': 1018, 'three': 1019, 'ticket': 1020, 'tip': 1021, 'total': 1022, 'tough': 1023, 'usually': 1024, 'vacation': 1025, 'weird': 1026, 'wife': 1027, 'wine': 1028, 'Almost': 1029, 'BE': 1030, 'Beautiful': 1031, 'Call': 1032, 'Congratulations': 1033, 'DO': 1034, 'Deepika': 1035, 'Doing': 1036, 'Down': 1037, 'Especially': 1038, 'Exercising': 1039, 'Free': 1040, 'GET': 1041, 'Gonna': 1042, 'HAVE': 1043, 'IN': 1044, 'John': 1045, 'Making': 1046, 'Miley': 1047, 'Nothing': 1048, 'PLEASE': 1049, 'Pensive': 1050, 'Power': 1051, 'REALLY': 1052, 'RT': 1053, 'Save': 1054, 'Since': 1055, 'Sometimes': 1056, 'South': 1057, 'Still': 1058, 'Sun': 1059, 'Sweet': 1060, 'Tom': 1061, 'Trump': 1062, 'UK': 1063, 'Waving': 1064, 'YAY': 1065, 'YOUR': 1066, 'ahead': 1067, 'aint': 1068, 'amount': 1069, 'apple': 1070, 'art': 1071, 'attempt': 1072, 'awareness': 1073, 'base': 1074, 'bear': 1075, 'benefit': 1076, 'bike': 1077, 'blood': 1078, 'brother': 1079, 'brothers': 1080, 'btw': 1081, 'bunch': 1082, 'case': 1083, 'cd': 1084, 'celebrate': 1085, 'challenge': 1086, 'character': 1087, 'clue': 1088, 'compare': 1089, 'cope': 1090, 'count': 1091, 'crash': 1092, 'death': 1093, 'delete': 1094, 'different': 1095, 'double': 1096, 'earn': 1097, 'emotional': 1098, 'encourage': 1099, 'escape': 1100, 'exams': 1101, 'excuse': 1102, 'fast': 1103, 'fell': 1104, 'field': 1105, 'five': 1106, 'folks': 1107, 'future': 1108, 'gender': 1109, 'girlfriend': 1110, 'girls': 1111, 'glass': 1112, 'graduate': 1113, 'greatest': 1114, 'homework': 1115, 'honestly': 1116, 'hotel': 1117, 'hubby': 1118, 'iPhone': 1119, 'imagine': 1120, 'imbalance': 1121, 'impress': 1122, 'inspire': 1123, 'july': 1124, 'la': 1125, 'lakers': 1126, 'land': 1127, 'legs': 1128, 'library': 1129, 'limit': 1130, 'memes': 1131, 'miles': 1132, 'mistake': 1133, 'month': 1134, 'myspace': 1135, 'nail': 1136, 'nearly': 1137, 'note': 1138, 'patients': 1139, 'piano': 1140, 'plus': 1141, 'pool': 1142, 'prefer': 1143, 'provide': 1144, 'quiet': 1145, 'regard': 1146, 'relieve': 1147, 'ride': 1148, 'saturday': 1149, 'secret': 1150, 'sense': 1151, 'service': 1152, 'several': 1153, 'shine': 1154, 'shirt': 1155, 'shoe': 1156, 'skip': 1157, 'sky': 1158, 'sore': 1159, 'spot': 1160, 'stigma': 1161, 'strange': 1162, 'student': 1163, 'students': 1164, 'swear': 1165, 'table': 1166, 'tea': 1167, 'teen': 1168, 'terrible': 1169, 'theres': 1170, 'thru': 1171, 'thx': 1172, 'towards': 1173, 'trauma': 1174, 'travel': 1175, 'treatment': 1176, 'trust': 1177, 'usual': 1178, 'voice': 1179, 'ward': 1180, 'waste': 1181, 'web': 1182, 'website': 1183, 'woman': 1184, 'yea': 1185, 'Also': 1186, 'Any': 1187, 'Anyone': 1188, 'BUT': 1189, 'Big': 1190, 'Both': 1191, 'Bout': 1192, 'Cat': 1193, 'City': 1194, 'D': 1195, 'DEATH': 1196, 'David': 1197, 'Facebook': 1198, 'Federal': 1199, 'Feeling': 1200, 'First': 1201, 'Food': 1202, 'From': 1203, 'Funny': 1204, 'GREAT': 1205, 'Game': 1206, 'Gettin': 1207, 'Gotta': 1208, 'HAPPY': 1209, 'HERE': 1210, 'Hanging': 1211, 'His': 1212, 'Hocking': 1213, 'Honestly': 1214, 'House': 1215, 'IM': 1216, 'ITS': 1217, 'July': 1218, 'Lakers': 1219, 'Listen': 1220, 'Long': 1221, 'Look': 1222, 'Made': 1223, 'Many': 1224, 'Movie': 1225, 'Must': 1226, 'NO': 1227, 'Obama': 1228, 'Out': 1229, 'Post': 1230, 'Real': 1231, 'Running': 1232, 'Same': 1233, 'Say': 1234, 'Sitting': 1235, 'Sleep': 1236, 'Slightly': 1237, 'Stay': 1238, 'Struggle': 1239, 'TV': 1240, 'Therapy': 1241, 'These': 1242, 'Think': 1243, 'Those': 1244, 'Two': 1245, 'VERY': 1246, 'WILL': 1247, 'Waiting': 1248, 'While': 1249, 'Working': 1250, 'absolutely': 1251, 'abt': 1252, 'accord': 1253, 'active': 1254, 'affect': 1255, 'alive': 1256, 'although': 1257, 'among': 1258, 'apart': 1259, 'artist': 1260, 'available': 1261, 'backhand': 1262, 'bet': 1263, 'beyond': 1264, 'bigger': 1265, 'biggest': 1266, 'bird': 1267, 'blend': 1268, 'block': 1269, 'blow': 1270, 'bowl': 1271, 'brush': 1272, 'burn': 1273, 'button': 1274, 'certainly': 1275, 'chemical': 1276, 'child': 1277, 'city': 1278, 'clearly': 1279, 'clinical': 1280, 'closer': 1281, 'clothe': 1282, 'colour': 1283, 'combat': 1284, 'completely': 1285, 'congratulations': 1286, 'connect': 1287, 'constant': 1288, 'constantly': 1289, 'convince': 1290, 'copy': 1291, 'country': 1292, 'cousin': 1293, 'crap': 1294, 'creative': 1295, 'credit': 1296, 'cross': 1297, 'daughter': 1298, 'david': 1299, 'dear': 1300, 'decision': 1301, 'decrease': 1302, 'drag': 1303, 'dry': 1304, 'earlier': 1305, 'economic': 1306, 'energy': 1307, 'event': 1308, 'evidence': 1309, 'except': 1310, 'expect': 1311, 'extra': 1312, 'fail': 1313, 'fake': 1314, 'fat': 1315, 'fave': 1316, 'football': 1317, 'form': 1318, 'freak': 1319, 'french': 1320, 'fresh': 1321, 'friday': 1322, 'gain': 1323, 'gay': 1324, 'gift': 1325, 'gorgeous': 1326, 'grill': 1327, 'gym': 1328, 'hahahaha': 1329, 'harm': 1330, 'havent': 1331, 'hill': 1332, 'hole': 1333, 'hows': 1334, 'idk': 1335, 'ignore': 1336, 'imma': 1337, 'impact': 1338, 'incredibly': 1339, 'information': 1340, 'inside': 1341, 'isnt': 1342, 'jonas': 1343, 'journey': 1344, 'joy': 1345, 'lady': 1346, 'list': 1347, 'load': 1348, 'local': 1349, 'log': 1350, 'lonely': 1351, 'mall': 1352, 'mama': 1353, 'maths': 1354, 'medicine': 1355, 'meds': 1356, 'miley': 1357, 'moms': 1358, 'moon': 1359, 'mouth': 1360, 'mum': 1361, 'muscle': 1362, 'negative': 1363, 'nobody': 1364, 'officially': 1365, 'older': 1366, 'opinion': 1367, 'per': 1368, 'pet': 1369, 'pig': 1370, 'pink': 1371, 'piss': 1372, 'pleasure': 1373, 'present': 1374, 'pressure': 1375, 'princess': 1376, 'productive': 1377, 'profit': 1378, 'project': 1379, 'prove': 1380, 'pub': 1381, 'rat': 1382, 'rather': 1383, 'reach': 1384, 'realise': 1385, 'recover': 1386, 'refer': 1387, 'sadness': 1388, 'sandwich': 1389, 'seasonal': 1390, 'sell': 1391, 'settle': 1392, 'shitty': 1393, 'shout': 1394, 'society': 1395, 'space': 1396, 'stalk': 1397, 'subject': 1398, 'sunshine': 1399, 'survive': 1400, 'taste': 1401, 'teacher': 1402, 'tend': 1403, 'thankyou': 1404, 'tool': 1405, 'town': 1406, 'trend': 1407, 'truth': 1408, 'tune': 1409, 'twice': 1410, 'twit': 1411, 'unless': 1412, 'warm': 1413, 'wasnt': 1414, 'watchin': 1415, 'ways': 1416, 'weed': 1417, 'whether': 1418, 'whilst': 1419, 'wild': 1420, 'within': 1421, 'workout': 1422, 'yard': 1423, 'yummy': 1424, 'AT': 1425, 'Addiction': 1426, 'Ah': 1427, 'Amazing': 1428, 'America': 1429, 'Americans': 1430, 'An': 1431, 'App': 1432, 'BB': 1433, 'BIG': 1434, 'BOM': 1435, 'Bom': 1436, 'Breakfast': 1437, 'Breastfeeding': 1438, 'British': 1439, 'Chicago': 1440, 'DAYS': 1441, 'Disney': 1442, 'Done': 1443, 'East': 1444, 'Epidemic': 1445, 'Ever': 1446, 'Everyone': 1447, 'FEEL': 1448, 'FUCK': 1449, 'Felt': 1450, 'Friends': 1451, 'Fuck': 1452, 'GO': 1453, 'Guess': 1454, 'HE': 1455, 'Hahaha': 1456, 'Harry': 1457, 'Heart': 1458, 'Home': 1459, 'Hopefully': 1460, 'Jonas': 1461, 'Ketamine': 1462, 'L': 1463, 'LIKE': 1464, 'LMAO': 1465, 'La': 1466, 'Learn': 1467, 'Lmao': 1468, 'London': 1469, 'Looks': 1470, 'Lucky': 1471, 'MTV': 1472, 'MUCH': 1473, 'Men': 1474, 'Might': 1475, 'Mom': 1476, 'Mr': 1477, 'National': 1478, 'O': 1479, 'Over': 1480, 'PM': 1481, 'Padukone': 1482, 'Park': 1483, 'Part': 1484, 'Person': 1485, 'Pouting': 1486, 'Pretty': 1487, 'Quite': 1488, 'Rock': 1489, 'Sims': 1490, 'Sleeping': 1491, 'Someone': 1492, 'Star': 1493, 'Started': 1494, 'Steve': 1495, 'Study': 1496, 'Suicidal': 1497, 'Super': 1498, 'Symptoms': 1499, 'THANK': 1500, 'TIME': 1501, 'Taco': 1502, 'Talking': 1503, 'Texas': 1504, 'Their': 1505, 'Things': 1506, 'Thinking': 1507, 'Tomorrow': 1508, 'Tony': 1509, 'Totally': 1510, 'Try': 1511, 'Tuesday': 1512, 'Tweet': 1513, 'WHAT': 1514, 'Weary': 1515, 'Woman': 1516, 'Women': 1517, 'XD': 1518, 'action': 1519, 'activity': 1520, 'addict': 1521, 'advice': 1522, 'alright': 1523, 'amazinggg': 1524, 'anger': 1525, 'anniversary': 1526, 'anytime': 1527, 'app': 1528, 'appointment': 1529, 'area': 1530, 'assignment': 1531, 'assume': 1532, 'attend': 1533, 'autograph': 1534, 'aw': 1535, 'background': 1536, 'ball': 1537, 'baseball': 1538, 'basically': 1539, 'bathroom': 1540, 'begin': 1541, 'behave': 1542, 'board': 1543, 'bom': 1544, 'bottle': 1545, 'breeze': 1546, 'brunch': 1547, 'cars': 1548, 'cheer': 1549, 'chicken': 1550, 'childhood': 1551, 'chocolate': 1552, 'choice': 1553, 'climb': 1554, 'clip': 1555, 'cnt': 1556, 'coach': 1557, 'combine': 1558, 'commit': 1559, 'common': 1560, 'competition': 1561, 'compliment': 1562, 'conference': 1563, 'confuse': 1564, 'content': 1565, 'cookies': 1566, 'coz': 1567, 'cup': 1568, 'currently': 1569, 'customer': 1570, 'cutest': 1571, 'de': 1572, 'debt': 1573, 'deeper': 1574, 'depend': 1575, 'diet': 1576, 'direct': 1577, 'discover': 1578, 'distance': 1579, 'doors': 1580, 'downtown': 1581, 'du': 1582, 'duloc': 1583, 'dun': 1584, 'dye': 1585, 'easily': 1586, 'emotions': 1587, 'empty': 1588, 'entire': 1589, 'epic': 1590, 'esp': 1591, 'expert': 1592, 'facebook': 1593, 'factor': 1594, 'fam': 1595, 'famous': 1596, 'fb': 1597, 'feet': 1598, 'female': 1599, 'flat': 1600, 'genuinely': 1601, 'global': 1602, 'google': 1603, 'grade': 1604, 'grandma': 1605, 'halfway': 1606, 'hangover': 1607, 'happiness': 1608, 'hella': 1609, 'heyy': 1610, 'honor': 1611, 'hook': 1612, 'hospital': 1613, 'host': 1614, 'however': 1615, 'hrs': 1616, 'hun': 1617, 'incredible': 1618, 'info': 1619, 'jst': 1620, 'jump': 1621, 'june': 1622, 'kiss': 1623, 'kitchen': 1624, 'ladies': 1625, 'leg': 1626, 'lie': 1627, 'likely': 1628, 'lmaooo': 1629, 'loneliness': 1630, 'macbook': 1631, 'magic': 1632, 'mail': 1633, 'main': 1634, 'majority': 1635, 'mark': 1636, 'mate': 1637, 'mild': 1638, 'millennials': 1639, 'mommy': 1640, 'mtv': 1641, 'near': 1642, 'noodles': 1643, 'nude': 1644, 'nurse': 1645, 'occur': 1646, 'orange': 1647, 'overall': 1648, 'overcome': 1649, 'pair': 1650, 'park': 1651, 'particular': 1652, 'passion': 1653, 'peep': 1654, 'perform': 1655, 'personality': 1656, 'picnic': 1657, 'pics': 1658, 'pizza': 1659, 'plenty': 1660, 'plz': 1661, 'possibly': 1662, 'prom': 1663, 'puff': 1664, 'quality': 1665, 'quarter': 1666, 'queen': 1667, 'quote': 1668, 'random': 1669, 'rare': 1670, 'recovery': 1671, 'refresh': 1672, 'regardless': 1673, 'reject': 1674, 'release': 1675, 'report': 1676, 'request': 1677, 'resources': 1678, 'review': 1679, 'revise': 1680, 'ring': 1681, 'role': 1682, 'row': 1683, 'rule': 1684, 'sa': 1685, 'sales': 1686, 'salt': 1687, 'sayin': 1688, 'scar': 1689, 'scary': 1690, 'schedule': 1691, 'seat': 1692, 'seek': 1693, 'shots': 1694, 'sister': 1695, 'snack': 1696, 'snap': 1697, 'solid': 1698, 'son': 1699, 'soup': 1700, 'spiral': 1701, 'spirit': 1702, 'sport': 1703, 'spring': 1704, 'stage': 1705, 'station': 1706, 'stock': 1707, 'strain': 1708, 'stream': 1709, 'studio': 1710, 'submit': 1711, 'suggestions': 1712, 'sushi': 1713, 'sway': 1714, 'swing': 1715, 'talented': 1716, 'tax': 1717, 'tempt': 1718, 'tennis': 1719, 'throw': 1720, 'ton': 1721, 'truck': 1722, 'twist': 1723, 'txt': 1724, 'unique': 1725, 'upon': 1726, 'version': 1727, 'victim': 1728, 'villainous': 1729, 'warn': 1730, 'wat': 1731, 'whenever': 1732, 'whoa': 1733, 'winter': 1734, 'wit': 1735, 'witness': 1736, 'women': 1737, 'wooo': 1738, 'wtf': 1739, 'xo': 1740, 'yayy': 1741, 'yr': 1742, 'yum': 1743, 'AMAZING': 1744, 'ANY': 1745, 'AP': 1746, 'ATL': 1747, 'Actually': 1748, 'Against': 1749, 'Alright': 1750, 'Always': 1751, 'Anchor': 1752, 'Angeles': 1753, 'Atlanta': 1754, 'Awards': 1755, 'Awesome': 1756, 'Awww': 1757, 'B': 1758, 'BEST': 1759, 'BY': 1760, 'Beating': 1761, 'Beer': 1762, 'Bell': 1763, 'Better': 1764, 'Bible': 1765, 'Bing': 1766, 'Blog': 1767, 'Bon': 1768, 'Book': 1769, 'Bought': 1770, 'Bowie': 1771, 'Bring': 1772, 'Brothers': 1773, 'C': 1774, 'Candy': 1775, 'Cant': 1776, 'Cheers': 1777, 'Chinese': 1778, 'Chocolate': 1779, 'Chris': 1780, 'Class': 1781, 'Coffee': 1782, 'College': 1783, 'Come': 1784, 'DC': 1785, 'Dear': 1786, 'Declan': 1787, 'Decrease': 1788, 'Differ': 1789, 'Dinner': 1790, 'Disappointed': 1791, 'Dont': 1792, 'Doubles': 1793, 'Dr': 1794, 'Drinking': 1795, 'Drive': 1796, 'Drove': 1797, 'Emily': 1798, 'Eye': 1799, 'FB': 1800, 'FOLLOW': 1801, 'FROM': 1802, 'FUCKING': 1803, 'Family': 1804, 'Find': 1805, 'Florida': 1806, 'Forgive': 1807, 'Forgot': 1808, 'Found': 1809, 'GOT': 1810, 'Goin': 1811, 'Golden': 1812, 'Google': 1813, 'HEY': 1814, 'HIS': 1815, 'Hannah': 1816, 'Hard': 1817, 'Harm': 1818, 'Harmful': 1819, 'Helps': 1820, 'High': 1821, 'Holy': 1822, 'Ice': 1823, 'Idk': 1824, 'Iron': 1825, 'JONAS': 1826, 'Jason': 1827, 'Jones': 1828, 'Kanye': 1829, 'Kid': 1830, 'Kool': 1831, 'LAST': 1832, 'LIFE': 1833, 'LOOK': 1834, 'LOVED': 1835, 'Lake': 1836, 'Leeds': 1837, 'Leicester': 1838, 'Lets': 1839, 'Los': 1840, 'Lovely': 1841, 'Loving': 1842, 'Luv': 1843, 'M': 1844, 'MAY': 1845, 'MORE': 1846, 'Makes': 1847, 'Media': 1848, 'Meditation': 1849, 'Michael': 1850, 'Mindfulness': 1851, 'Miss': 1852, 'Much': 1853, 'Museum': 1854, 'NEED': 1855, 'NEVER': 1856, 'NZ': 1857, 'Nearly': 1858, 'Nighttime': 1859, 'Note': 1860, 'OH': 1861, 'OR': 1862, 'OUR': 1863, 'Okay': 1864, 'Omg': 1865, 'Orlando': 1866, 'PT': 1867, 'Pain': 1868, 'Paris': 1869, 'Perhaps': 1870, 'Persevering': 1871, 'Phrases': 1872, 'Pls': 1873, 'Police': 1874, 'Poor': 1875, 'Potentially': 1876, 'Probably': 1877, 'Promise': 1878, 'Radio': 1879, 'Reading': 1880, 'Ready': 1881, 'Really': 1882, 'Remember': 1883, 'Richard': 1884, 'Robert': 1885, 'SEE': 1886, 'SF': 1887, 'San': 1888, 'Sat': 1889, 'Saw': 1890, 'School': 1891, 'Searching': 1892, 'Seattle': 1893, 'Second': 1894, 'Self': 1895, 'Sexy': 1896, 'Share': 1897, 'Show': 1898, 'Shows': 1899, 'Six': 1900, 'Skype': 1901, 'Something': 1902, 'Sooo': 1903, 'Spent': 1904, 'Such': 1905, 'Summer': 1906, 'Surgery': 1907, 'THEN': 1908, 'TOTALLY': 1909, 'Talk': 1910, 'Thats': 1911, 'Third': 1912, 'Thnx': 1913, 'Thomas': 1914, 'Though': 1915, 'Thx': 1916, 'Tired': 1917, 'Together': 1918, 'Tonight': 1919, 'Took': 1920, 'Toronto': 1921, 'Trek': 1922, 'Turn': 1923, 'Twilight': 1924, 'Twittering': 1925, 'Update': 1926, 'Ur': 1927, 'Using': 1928, 'Victoria': 1929, 'Vintage': 1930, 'Visit': 1931, 'Vote': 1932, 'WAIT': 1933, 'WHY': 1934, 'WOW': 1935, 'War': 1936, 'Watch': 1937, 'Weekend': 1938, 'Wild': 1939, 'Woke': 1940, 'Wonder': 1941, 'Xx': 1942, 'Yesterday': 1943, 'Yet': 1944, 'Yoga': 1945, 'across': 1946, 'adam': 1947, 'address': 1948, 'adorable': 1949, 'adult': 1950, 'af': 1951, 'aim': 1952, 'airport': 1953, 'andy': 1954, 'anymore': 1955, 'apartment': 1956, 'approach': 1957, 'arent': 1958, 'arm': 1959, 'arts': 1960, 'avatar': 1961, 'award': 1962, 'awsome': 1963, 'babe': 1964, 'bake': 1965, 'balloon': 1966, 'barely': 1967, 'bark': 1968, 'bay': 1969, 'bb': 1970, 'beauty': 1971, 'bedroom': 1972, 'beers': 1973, 'behavior': 1974, 'bein': 1975, 'bill': 1976, 'bleach': 1977, 'bloody': 1978, 'boat': 1979, 'boss': 1980, 'bottom': 1981, 'box': 1982, 'brand': 1983, 'bro': 1984, 'bubble': 1985, 'butter': 1986, 'c': 1987, 'calm': 1988, 'camp': 1989, 'candy': 1990, 'card': 1991, 'career': 1992, 'careful': 1993, 'cash': 1994, 'certain': 1995, 'charity': 1996, 'chase': 1997, 'cheese': 1998, 'chick': 1999, 'chores': 2000, 'church': 2001, 'claim': 2002, 'click': 2003, 'cloud': 2004, 'collect': 2005, 'collection': 2006, 'community': 2007, 'comp': 2008, 'company': 2009, 'complete': 2010, 'concern': 2011, 'confirm': 2012, 'connection': 2013, 'consume': 2014, 'conversations': 2015, 'cop': 2016, 'corn': 2017, 'corner': 2018, 'creep': 2019, 'cruel': 2020, 'curious': 2021, 'curly': 2022, 'cycle': 2023, 'daddy': 2024, 'dare': 2025, 'debate': 2026, 'deck': 2027, 'definition': 2028, 'delicious': 2029, 'demi': 2030, 'despite': 2031, 'dia': 2032, 'diagnosis': 2033, 'differences': 2034, 'differently': 2035, 'difficulty': 2036, 'diploma': 2037, 'dirty': 2038, 'display': 2039, 'doesnt': 2040, 'dollars': 2041, 'donate': 2042, 'dp': 2043, 'duck': 2044, 'dumb': 2045, 'easier': 2046, 'easter': 2047, 'edit': 2048, 'education': 2049, 'effort': 2050, 'eight': 2051, 'embarrass': 2052, 'engineer': 2053, 'equal': 2054, 'essay': 2055, 'events': 2056, 'eventually': 2057, 'everytime': 2058, 'excellent': 2059, 'experts': 2060, 'extreme': 2061, 'fa': 2062, 'fabulous': 2063, 'fair': 2064, 'fear': 2065, 'feature': 2066, 'fee': 2067, 'fellow': 2068, 'festival': 2069, 'fever': 2070, 'finale': 2071, 'finals': 2072, 'flight': 2073, 'floor': 2074, 'fm': 2075, 'fold': 2076, 'fool': 2077, 'forgive': 2078, 'forth': 2079, 'freedom': 2080, 'frequent': 2081, 'fruit': 2082, 'frustrate': 2083, 'fry': 2084, 'fuckin': 2085, 'gas': 2086, 'gear': 2087, 'gig': 2088, 'goal': 2089, 'goals': 2090, 'goodmorning': 2091, 'gooood': 2092, 'grad': 2093, 'grateful': 2094, 'grief': 2095, 'guilty': 2096, 'gunna': 2097, 'gut': 2098, 'hahahah': 2099, 'hannah': 2100, 'happier': 2101, 'harder': 2102, 'heat': 2103, 'heavy': 2104, 'heck': 2105, 'hes': 2106, 'highest': 2107, 'hilarious': 2108, 'hittin': 2109, 'hmm': 2110, 'hmmm': 2111, 'horse': 2112, 'hott': 2113, 'huh': 2114, 'hunt': 2115, 'ideas': 2116, 'identify': 2117, 'ima': 2118, 'image': 2119, 'index': 2120, 'individual': 2121, 'individuals': 2122, 'inform': 2123, 'innocent': 2124, 'inspiration': 2125, 'instagram': 2126, 'insult': 2127, 'ipod': 2128, 'itunes': 2129, 'jeans': 2130, 'jk': 2131, 'killer': 2132, 'kings': 2133, 'knee': 2134, 'label': 2135, 'lads': 2136, 'language': 2137, 'letter': 2138, 'lmfao': 2139, 'london': 2140, 'loose': 2141, 'loud': 2142, 'maintain': 2143, 'manic': 2144, 'manifest': 2145, 'mat': 2146, 'math': 2147, 'mcfly': 2148, 'medicate': 2149, 'meditation': 2150, 'member': 2151, 'memory': 2152, 'mentally': 2153, 'mess': 2154, 'mindset': 2155, 'mini': 2156, 'minor': 2157, 'mins': 2158, 'miserable': 2159, 'modern': 2160, 'museum': 2161, 'musical': 2162, 'nah': 2163, 'neck': 2164, 'nick': 2165, 'nightmares': 2166, 'non': 2167, 'none': 2168, 'normally': 2169, 'north': 2170, 'nose': 2171, 'obsession': 2172, 'obtain': 2173, 'obviously': 2174, 'offend': 2175, 'official': 2176, 'ohh': 2177, 'ol': 2178, 'onto': 2179, 'ordinary': 2180, 'otherwise': 2181, 'outfit': 2182, 'outlet': 2183, 'owe': 2184, 'pant': 2185, 'peaceful': 2186, 'physically': 2187, 'pills': 2188, 'plain': 2189, 'plane': 2190, 'possible': 2191, 'postnatal': 2192, 'practice': 2193, 'prayer': 2194, 'pregnancy': 2195, 'price': 2196, 'prison': 2197, 'prob': 2198, 'product': 2199, 'profile': 2200, 'promote': 2201, 'public': 2202, 'puppy': 2203, 'pussy': 2204, 'rabbit': 2205, 'rap': 2206, 'receive': 2207, 'recently': 2208, 'recession': 2209, 'recipe': 2210, 'recognition': 2211, 'refuse': 2212, 'regret': 2213, 'relationships': 2214, 'remove': 2215, 'repeat': 2216, 'researchers': 2217, 'respect': 2218, 'retweet': 2219, 'revolve': 2220, 'roof': 2221, 'root': 2222, 'rough': 2223, 'rt': 2224, 'rub': 2225, 'sadly': 2226, 'salad': 2227, 'scream': 2228, 'screen': 2229, 'serve': 2230, 'server': 2231, 'session': 2232, 'shadow': 2233, 'shape': 2234, 'shareholder': 2235, 'shed': 2236, 'shift': 2237, 'shin': 2238, 'shud': 2239, 'silence': 2240, 'silly': 2241, 'sims': 2242, 'sink': 2243, 'sir': 2244, 'sis': 2245, 'situation': 2246, 'situations': 2247, 'size': 2248, 'skinny': 2249, 'sleepy': 2250, 'slip': 2251, 'slowly': 2252, 'sluggish': 2253, 'smarter': 2254, 'solo': 2255, 'somebody': 2256, 'someday': 2257, 'somehow': 2258, 'speech': 2259, 'sponsor': 2260, 'spy': 2261, 'stag': 2262, 'starbucks': 2263, 'steal': 2264, 'stoke': 2265, 'stomach': 2266, 'stone': 2267, 'strawberries': 2268, 'stronger': 2269, 'sudden': 2270, 'sum': 2271, 'supplement': 2272, 'surely': 2273, 'surgery': 2274, 'taboo': 2275, 'taco': 2276, 'talent': 2277, 'tan': 2278, 'teeth': 2279, 'thankful': 2280, 'therapist': 2281, 'tix': 2282, 'tmrw': 2283, 'tom': 2284, 'tonite': 2285, 'tons': 2286, 'topic': 2287, 'tragic': 2288, 'trailer': 2289, 'trash': 2290, 'tree': 2291, 'tryna': 2292, 'ugly': 2293, 'uncle': 2294, 'uni': 2295, 'up': 2296, 'upgrade': 2297, 'upset': 2298, 'useful': 2299, 'validation': 2300, 'vet': 2301, 'videos': 2302, 'vodka': 2303, 'vs': 2304, 'wave': 2305, 'weak': 2306, 'wee': 2307, 'west': 2308, 'whip': 2309, 'wicked': 2310, 'wide': 2311, 'wif': 2312, 'will': 2313, 'wind': 2314, 'window': 2315, 'wonderfully': 2316, 'workers': 2317, 'wouldnt': 2318, 'writers': 2319, 'yoga': 2320, 'yogurt': 2321, 'youtube': 2322, 'zoo': 2323})\n"
     ]
    }
   ],
   "source": [
    "#initialize glove embeddings\n",
    "TEXT.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.100d\")  \n",
    "\n",
    "#No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "#No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
    "\n",
    "#Commonly used words\n",
    "print(TEXT.vocab.freqs.most_common(10))  \n",
    "\n",
    "#Word dictionary\n",
    "print(TEXT.vocab.stoi)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "#set batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "#Load an iterator\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    device = device)\n",
    "test_iterator = data.BucketIterator(\n",
    "    test_data, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation And Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \n",
    "    #define all the layers used in model\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout,nonlinearity):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()          \n",
    "        \n",
    "        #embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #rnn layer\n",
    "        self.rnn = nn.RNN(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True,\n",
    "                           nonlinearity=nonlinearity)\n",
    "        \n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        #activation function\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [batch size,sent_length]\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent_len, emb dim]\n",
    "      \n",
    "        #packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(),batch_first=True)\n",
    "        #####################################################\n",
    "        packed_output, hidden = self.rnn(packed_embedded)\n",
    "        #hidden = [batch size, num layers * num directions,hid dim]\n",
    "        #cell = [batch size, num layers * num directions,hid dim]\n",
    "        \n",
    "        #concat the final forward and backward hidden state\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs=self.fc(hidden)\n",
    "\n",
    "        #Final activation function\n",
    "        outputs=self.act(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define hyperparameters\n",
    "size_of_vocab = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "num_hidden_nodes = 64\n",
    "num_output_nodes = 1\n",
    "num_layers = 4\n",
    "bidirection = False\n",
    "dropout = 0.2\n",
    "lr = 0.0001\n",
    "#instantiate the model\n",
    "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n",
    "                   bidirectional = True, dropout = dropout,nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (embedding): Embedding(2324, 100)\n",
      "  (rnn): RNN(100, 64, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (act): Sigmoid()\n",
      ")\n",
      "The model has 328,273 trainable parameters\n",
      "torch.Size([2324, 100])\n"
     ]
    }
   ],
   "source": [
    "#architecture\n",
    "print(model)\n",
    "\n",
    "#No. of trianable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "#Initialize the pretrained embedding\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#define optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "#define metric\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "    \n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "    \n",
    "#push to cuda if available\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    #initialize every epoch \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    #set the model in training phase\n",
    "    model.train()  \n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        #retrieve text and no. of words\n",
    "        text, text_lengths = batch.text   \n",
    "        \n",
    "        #convert to 1D tensor\n",
    "        predictions = model(text, text_lengths).squeeze()  \n",
    "        \n",
    "        #compute the loss\n",
    "        loss = criterion(predictions, batch.label)        \n",
    "        \n",
    "        #compute the binary accuracy\n",
    "        acc = binary_accuracy(predictions, batch.label)   \n",
    "        \n",
    "        #backpropage the loss and compute the gradients\n",
    "        loss.backward()       \n",
    "        \n",
    "        #update the weights\n",
    "        optimizer.step()      \n",
    "        \n",
    "        #loss and accuracy\n",
    "        epoch_loss += loss.item()  \n",
    "        epoch_acc += acc.item()    \n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    #initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    #deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    #deactivates autograd\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "        \n",
    "            #retrieve text and no. of words\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            #convert to 1d tensor\n",
    "            predictions = model(text, text_lengths).squeeze()\n",
    "            \n",
    "            #compute loss and accuracy\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            \n",
    "            #keep track of loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, iterator, optimizer):\n",
    "    \n",
    "    #initialize every epoch \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    #set the model in training phase\n",
    "    model.train()  \n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        #retrieve text and no. of words\n",
    "        text, text_lengths = batch.text   \n",
    "        \n",
    "        #convert to 1D tensor\n",
    "        predictions = model(text, text_lengths).squeeze()  \n",
    "             \n",
    "        \n",
    "        #compute the binary accuracy\n",
    "        acc = binary_accuracy(predictions, batch.label)   \n",
    "        \n",
    "        #backpropage the loss and compute the gradients\n",
    "        loss.backward()       \n",
    "        \n",
    "        #update the weights\n",
    "        optimizer.step()      \n",
    "           \n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch:1\n",
      "\tTrain Loss: 0.071 | Train Acc: 97.88%\n",
      "\t Val. Loss: 0.149 |  Val. Acc: 95.81%\n",
      "\tEpoch:2\n",
      "\tTrain Loss: 0.071 | Train Acc: 97.78%\n",
      "\t Val. Loss: 0.148 |  Val. Acc: 95.93%\n",
      "\tEpoch:3\n",
      "\tTrain Loss: 0.069 | Train Acc: 97.82%\n",
      "\t Val. Loss: 0.154 |  Val. Acc: 95.87%\n",
      "\tEpoch:4\n",
      "\tTrain Loss: 0.066 | Train Acc: 98.03%\n",
      "\t Val. Loss: 0.156 |  Val. Acc: 95.63%\n",
      "\tEpoch:5\n",
      "\tTrain Loss: 0.060 | Train Acc: 98.14%\n",
      "\t Val. Loss: 0.160 |  Val. Acc: 95.93%\n",
      "\tEpoch:6\n",
      "\tTrain Loss: 0.060 | Train Acc: 98.02%\n",
      "\t Val. Loss: 0.158 |  Val. Acc: 95.93%\n",
      "\tEpoch:7\n",
      "\tTrain Loss: 0.057 | Train Acc: 98.17%\n",
      "\t Val. Loss: 0.154 |  Val. Acc: 96.11%\n",
      "\tEpoch:8\n",
      "\tTrain Loss: 0.052 | Train Acc: 98.39%\n",
      "\t Val. Loss: 0.168 |  Val. Acc: 95.87%\n",
      "\tEpoch:9\n",
      "\tTrain Loss: 0.048 | Train Acc: 98.51%\n",
      "\t Val. Loss: 0.164 |  Val. Acc: 95.99%\n",
      "\tEpoch:10\n",
      "\tTrain Loss: 0.045 | Train Acc: 98.61%\n",
      "\t Val. Loss: 0.176 |  Val. Acc: 95.57%\n",
      "\tEpoch:11\n",
      "\tTrain Loss: 0.047 | Train Acc: 98.42%\n",
      "\t Val. Loss: 0.168 |  Val. Acc: 95.93%\n",
      "\tEpoch:12\n",
      "\tTrain Loss: 0.038 | Train Acc: 98.93%\n",
      "\t Val. Loss: 0.191 |  Val. Acc: 95.75%\n",
      "\tEpoch:13\n",
      "\tTrain Loss: 0.040 | Train Acc: 98.68%\n",
      "\t Val. Loss: 0.186 |  Val. Acc: 95.57%\n",
      "\tEpoch:14\n",
      "\tTrain Loss: 0.034 | Train Acc: 98.94%\n",
      "\t Val. Loss: 0.191 |  Val. Acc: 95.93%\n",
      "\tEpoch:15\n",
      "\tTrain Loss: 0.034 | Train Acc: 98.90%\n",
      "\t Val. Loss: 0.209 |  Val. Acc: 95.63%\n",
      "\tEpoch:16\n",
      "\tTrain Loss: 0.030 | Train Acc: 99.03%\n",
      "\t Val. Loss: 0.203 |  Val. Acc: 95.45%\n",
      "\tEpoch:17\n",
      "\tTrain Loss: 0.031 | Train Acc: 99.05%\n",
      "\t Val. Loss: 0.201 |  Val. Acc: 95.81%\n",
      "\tEpoch:18\n",
      "\tTrain Loss: 0.045 | Train Acc: 98.54%\n",
      "\t Val. Loss: 0.191 |  Val. Acc: 95.45%\n",
      "\tEpoch:19\n",
      "\tTrain Loss: 0.032 | Train Acc: 98.92%\n",
      "\t Val. Loss: 0.189 |  Val. Acc: 95.87%\n",
      "\tEpoch:20\n",
      "\tTrain Loss: 0.026 | Train Acc: 99.19%\n",
      "\t Val. Loss: 0.204 |  Val. Acc: 95.99%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    \n",
    "    #evaluate the model\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    print(f'\\tEpoch:{epoch+1}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction, Accuracy Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "\n",
    "def test(model, iterator, version='title', threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            labels = batch.label.to(device)\n",
    "            text = text.to(device)\n",
    "            text_len = text_lengths.to(device)\n",
    "            output = model(text, text_lengths)\n",
    "\n",
    "            output = (output > threshold).int()\n",
    "            y_pred.extend(output.tolist())\n",
    "            y_true.extend(labels.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['NON-DEPRESSIVE', 'DEPRESSIVE'])\n",
    "    ax.yaxis.set_ticklabels(['NON-DEPRESSIVE', 'DEPRESSIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load weights\n",
    "path='saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path));\n",
    "model.eval();\n",
    "\n",
    "#inference \n",
    "import spacy\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "def predict(model, sentence):\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  #tokenize the sentence \n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]          #convert to integer sequence\n",
    "    length = [len(indexed)]                                    #compute no. of words\n",
    "    tensor = torch.LongTensor(indexed).to(device)              #convert to tensor\n",
    "    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\n",
    "    length_tensor = torch.LongTensor(length)                   #convert to tensor\n",
    "    prediction = model(tensor, length_tensor)                  #prediction \n",
    "    pred = prediction.cpu().detach().numpy()\n",
    "    if pred[0] > 0.5:\n",
    "        print('(\"',sentence,'\") Prediction: Depressive :(')\n",
    "    else:\n",
    "        print('(\"',sentence,'\") Prediction: Non-Depressive :)')\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9696    0.8415    0.9010       492\n",
      "           0     0.9513    0.9915    0.9710      1537\n",
      "\n",
      "    accuracy                         0.9552      2029\n",
      "   macro avg     0.9604    0.9165    0.9360      2029\n",
      "weighted avg     0.9557    0.9552    0.9540      2029\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(model, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\" This assignment got me into depression \") Prediction: Depressive :(\n",
      "(\" After finishing it i can die in peace!LOL! \") Prediction: Non-Depressive :)\n",
      "(\" I am so Happy! \") Prediction: Non-Depressive :)\n"
     ]
    }
   ],
   "source": [
    "#make predictions\n",
    "predict(model, \"This assignment got me into depression\")\n",
    "predict(model, \"After finishing it i can die in peace!LOL!\")\n",
    "predict(model, \"I am so Happy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
